lightning
torchmetrics
timm  
transformers  
flash-attn @https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl#sha256=237ef9c6157db394e1ddde4ba609a21ebb98382377a27041edc09318801a6f24

hydra-core==1.3.2
hydra-colorlog==1.2.0
hydra-optuna-sweeper==1.2.0

wandb

rootutils       
pre-commit     
rich            
pytest          
ipdb            
opencv-python   
fvcore          
einops        
tqdm            
matplotlib
scikit-learn
pandas
zstandard
