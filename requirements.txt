lightning
torchmetrics
timm  
transformers  
flash-attn @https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.4cxx11abiFALSE-cp311-cp311-linux_x86_64.whl#sha256=25405479af3f6865c873ee3bbdfadcfccea9055355de78e7cd6b93170e9d4377

hydra-core==1.3.2
hydra-colorlog==1.2.0
hydra-optuna-sweeper==1.2.0

wandb

rootutils       
pre-commit     
rich            
pytest          
ipdb            
opencv-python   
fvcore          
einops        
tqdm            
matplotlib
scikit-learn
pandas
peft
nibabel
zstandard
